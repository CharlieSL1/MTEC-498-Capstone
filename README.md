# MTEC-498-Capstone
# PanGu — Spatial Audio, Live Phase Controller & Composition Assistant
- [PanGu_V1](PanGu_V1.jpg)
- [PanGu_Flow_Chart](PanGu.png)
- [PanGu_ppt](PanGu.pdf)

> **Elevator Pitch**  
> A next-generation **spatial audio performance platform**: a wearable, arm-mounted **Circle MIDI controller** that lets you **select a position in 3D space** and then **instantly play/place sounds there**—turning spatial audio into an expressive **instrument** for composition and live performance.

---

## Table of Contents
- [Project Overview](#project-overview)
  - [Problem Statement](#problem-statement)
  - [Creative Vision](#creative-vision)
  - [Significance](#significance)
  - [Personal Connection](#personal-connection)
- [Users & Needs](#users--needs)
  - [Primary Users](#primary-users)
  - [Use Cases](#use-cases)
  - [User Needs](#user-needs)
- [Why Me](#why-me)
- [Technical Specifications](#technical-specifications)
- [Influences & Inspirations](#influences--inspirations)
- [Project Timeline](#project-timeline)
- [Risk & Mitigation](#risk--mitigation)
- [Next Steps](#next-steps)
- [Beyond This Semester](#beyond-this-semester)
- [Contact](#contact)
- [Credits](#credits)

---

## Project Overview

### Problem Statement
Current music creation/performance tools for spatial audio are either **too technical** (post-production/DAW-bound) or **too experimental** (unreliable gestures, weak integration). Musicians lack an **intuitive, real-time** way to treat sound as a **tangible object** that can be positioned and **performed** in space.

### Creative Vision
Build a platform that makes sound feel **grabbable**. Combine a **pan controller** with a **wearable hexagonal MIDI interface** so musicians can first **select 3D positions** and then **perform** them—transforming spatial audio from an engineering task into a **new instrument**.

### Significance
Spatial audio is expanding across **gaming, VR/AR, film, and live music**. Tools lag in **accessibility** and **playability**. This project bridges **cutting-edge spatialization** with **embodied performance**, offering an **intuitive, expressive** path into immersive sound.

### Personal Connection
As a **composer–technologist**, I feel the gap between **imagined spatial sound** and **cumbersome tooling**. This project aims to **collapse that gap**—making spatial design as immediate as **strumming a chord** or **hitting a drum**.

---

## Users & Needs

### Primary Users
Musicians, producers, sound artists, and audiences exploring **new performance formats**.

### Use Cases
- **Studio**: Rapidly test spatial effects during composition/production.  
- **Live Performance**: Use as an **expressive instrument** for immersive shows.  
- **Art Exhibitions**: Let audiences **intuitively interact** with spatial audio.

### User Needs
**Intuitive control**, **real-time feedback**, and **low learning barriers**—turning spatial audio from complex tooling into an **accessible performance medium**.

---

## Why Me
- **Relevant Coursework**: EDI prototyping; Programming in C; Programming in Max  
- **Previous Projects**: *Box of World*; *Ultra Sonic Headphone*  
- **Personal Interests**: Multichannel composer; music-tech developer  
- **Technical Strengths**: Python, C/C++, Max/MSP, circuit design  
- **Learning Goals**: Deepen **spatial audio** skills

---

## Technical Specifications
**Programming Languages**: Python, C/C++, Max  
**Frameworks/Libraries**: Max/MSP; Arduino ecosystem  
**Audio Technologies**: TorchAudio; DSP  
**AI/ML**: PyTorch; scikit-learn; NumPy

---

## Influences & Inspirations
- **Lumatone** *(Product)* — rethinking playing/performing systems  
- **MiMU Gloves** *(Product)* — making creation **fun** and **immersive**  
- **PanMan** *(NIME Paper)* — approaches to **panning** and **modularizing** spatial components

---

## Project Timeline

| Phase | Weeks | Focus |
|---|---|---|
| **Phase 1** | 1–3 | Component checks; sensor bring-up; circuit design |
| **Phase 2** | 4–7 | 3D modeling & printing; tech development |
| **Phase 3** | 8–10 | OS/UX design; continued tech development |
| **Phase 4** | 11–13 | Iteration & improvements |
| **Phase 5** | 14–15 | Paper writing; function checks; mini-performance (NIME) |

---

## Risk & Mitigation
- **Technical (Latency)** → Improve **I/O** paths  
- **Hardware (Endurance)** → **Larger battery** / power optimization  
- **Creative (Outfit/Industrial Design)** → **80/20** approach; better textures & 3D finishes  
- **Project Scope (Too many features)** → Strict **modularization**; stage-gated delivery

---

## Next Steps
- **Repository**: *https://github.com/CharlieSL1/MTEC-498-Capstone.git*  
- **Collaboration**: Open to peer feedback & partnerships  
- **Office Hours**: Mon 1–9 pm; Tue 1–4 pm; Fri 1–6 pm  
- **Email**: cshi@berklee.edu

---

## Beyond This Semester
- **Version 2.0**: Standalone instrument (no computer); **pre-install instruments** for stage use  
- **Scalability**: A **new paradigm** of MIDI keyboard  
- **Team**: EE engineer; product designer; DSP engineer; AI engineer  
- **Commercial Potential**: **Viable as a product**  
- **Research Opportunities**: Explore **creative–AI co-working** and spatial performance cognition

---

## Contact
**Charlie Shi**  
cshi@berklee.edu

---

## Credits
*“Li SHi - Concept Develop and Design.”*
*“Xinyu Li - Sketch & Design”*
*”Special Thanks - Akito van Troyer“*
